"""
Amazon ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»å‰å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›®çš„ï¼š
1. Amazonå•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹
2. ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»å‰å‡¦ç†ã™ã‚‹  
3. æ„Ÿæƒ…åˆ†æç”¨ã®ãƒ©ãƒ™ãƒ«ï¼ˆpositive/negative/neutralï¼‰ã‚’ä»˜ã‘ã‚‹
4. CSVãƒ•ã‚¡ã‚¤ãƒ«ã§ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
5. ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’åˆ†æãƒ»è¡¨ç¤ºã™ã‚‹

"""

import kaggle
import pandas as pd         
import numpy as np   
import os             
from typing import Dict, List, Optional 
from tqdm import tqdm  
import json          
from datetime import datetime, timedelta


class AmazonReviewCollector:
    """
    Amazon ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»å‰å‡¦ç†ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, data_dir: str = "data"):
        """
        ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–ï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆæ™‚ã«æœ€åˆã«å®Ÿè¡Œã•ã‚Œã‚‹ï¼‰
        
        Args:
            data_dir (str): ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå
                          ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ "data" ãƒ•ã‚©ãƒ«ãƒ€
        """
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        self.data_dir = data_dir
        self.ensure_data_dir()  # ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        
        # å•†å“ã‚«ãƒ†ã‚´ãƒªã®å®šç¾©ï¼ˆåˆ†æå¯¾è±¡ã‚’æ˜ç¢ºã«ï¼‰
        self.target_categories = {
            "electronics": ["å……é›»å™¨", "ã‚¤ãƒ¤ãƒ›ãƒ³", "ã‚±ãƒ¼ãƒ–ãƒ«", "ãƒãƒƒãƒ†ãƒªãƒ¼"],
            "books": ["ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æœ¬", "ãƒ“ã‚¸ãƒã‚¹æ›¸", "è‡ªå·±å•“ç™ºæœ¬"],
            "daily_goods": ["ã‚­ãƒƒãƒãƒ³ç”¨å“", "æƒé™¤ç”¨å…·", "åç´ãƒœãƒƒã‚¯ã‚¹"]
        }
        
        # å¥½è©•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆé«˜è©•ä¾¡ã®å ´åˆã«ä½¿ç”¨ï¼‰
        self.positive_patterns = [
            "ã¨ã¦ã‚‚è‰¯ã„å•†å“ã§ã™ã€‚å“è³ªãŒé«˜ãã€é•·ãä½¿ãˆãã†ã§ã™ã€‚",
            "æœŸå¾…ä»¥ä¸Šã®æ€§èƒ½ã§ã—ãŸã€‚è²·ã£ã¦è‰¯ã‹ã£ãŸã§ã™ã€‚",
            "ãƒ‡ã‚¶ã‚¤ãƒ³ãŒç´ æ™´ã‚‰ã—ãã€ä½¿ã„ã‚„ã™ã„ã§ã™ã€‚",
            "ã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæœ€é«˜ã§ã™ã€‚ãŠã™ã™ã‚ã—ã¾ã™ã€‚",
            "é…é€ã‚‚æ—©ãã€æ¢±åŒ…ã‚‚ä¸å¯§ã§ã—ãŸã€‚ã¾ãŸåˆ©ç”¨ã—ãŸã„ã§ã™ã€‚",
            "æ€ã£ã¦ã„ãŸã‚ˆã‚Šè‰¯ã„å“è³ªã§æº€è¶³ã—ã¦ã„ã¾ã™ã€‚",
            "å€¤æ®µã®å‰²ã«æ©Ÿèƒ½ãŒå……å®Ÿã—ã¦ã„ã¦é©šãã¾ã—ãŸã€‚",
            "ä½¿ã„ã‚„ã™ãã¦ã€æ¯æ—¥æ„›ç”¨ã—ã¦ã„ã¾ã™ã€‚"
        ]
        
        # å®šè©•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä½è©•ä¾¡ã®å ´åˆã«ä½¿ç”¨ï¼‰
        self.negative_patterns = [
            "å“è³ªãŒæœŸå¾…ã‚ˆã‚Šä½ãã€ã™ãã«å£Šã‚Œã¾ã—ãŸã€‚",
            "èª¬æ˜ã¨å®Ÿéš›ã®å•†å“ãŒé•ã„ã¾ã—ãŸã€‚æ®‹å¿µã§ã™ã€‚",
            "ä¾¡æ ¼ã«è¦‹åˆã‚ãªã„å“è³ªã ã¨æ€ã„ã¾ã™ã€‚",
            "ä½¿ã„ã«ããã€æœŸå¾…ã—ã¦ã„ãŸã‚ˆã‚Šä¸ä¾¿ã§ã™ã€‚",
            "å……é›»é€Ÿåº¦ãŒé…ãã€æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¾ã™ã€‚",
            "éŸ³è³ªãŒæ‚ªãã€ãƒã‚¤ã‚ºãŒæ°—ã«ãªã‚Šã¾ã™ã€‚",
            "å±Šã„ãŸå•†å“ã«å‚·ãŒã‚ã‚Šã¾ã—ãŸã€‚",
            "ã‚µã‚¤ã‚ºãŒæ€ã£ã¦ã„ãŸã‚ˆã‚Šå°ã•ãã¦ä½¿ã„ã¥ã‚‰ã„ã§ã™ã€‚"
        ]
        
        # æ™®é€šãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.neutral_patterns = [
            "æ™®é€šã®å•†å“ã ã¨æ€ã„ã¾ã™ã€‚å¯ã‚‚ãªãä¸å¯ã‚‚ãªãã€‚",
            "å€¤æ®µç›¸å¿œã®å“è³ªã§ã™ã€‚ç‰¹ã«å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
            "æœŸå¾…ã—ã¦ã„ãŸé€šã‚Šã®å•†å“ã§ã—ãŸã€‚",
            "ä½¿ãˆã¾ã™ãŒã€ç‰¹åˆ¥è‰¯ã„ã¨ã„ã†ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
            "æ¨™æº–çš„ãªå•†å“ã§ã™ã€‚å¿…è¦æœ€ä½é™ã®æ©Ÿèƒ½ã¯ã‚ã‚Šã¾ã™ã€‚"
        ]
    
    def ensure_data_dir(self):
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèªãƒ»ä½œæˆ
        
        ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå®Ÿè¡Œã•ã‚Œã‚‹å‰ã«ã€ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒ
        å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã€ãªã‘ã‚Œã°ä½œæˆ
        """
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)  # ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {self.data_dir}")
    
    def setup_kaggle_api(self):
        """
        Kaggle API ã®è¨­å®š
        kaggle.json ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªå ´æ‰€ã«é…ç½®
        """
        import os
        import shutil
        
        # Kaggle èªè¨¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™
        kaggle_dir = os.path.expanduser("~/.kaggle")
        if not os.path.exists(kaggle_dir):
            os.makedirs(kaggle_dir)
        
        # kaggle.json ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ï¼‰
        if os.path.exists("kaggle.json"):
            shutil.copy("kaggle.json", os.path.join(kaggle_dir, "kaggle.json"))
            os.chmod(os.path.join(kaggle_dir, "kaggle.json"), 0o600)
            print("Kaggle APIèªè¨¼è¨­å®šå®Œäº†")
        else:
            print("kaggle.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    def load_real_kaggle_dataset(self, dataset_name: str = "snap/amazon-fine-food-reviews") -> pd.DataFrame:
        """
        å®Ÿéš›ã®Kaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å–å¾—ãƒ»å‡¦ç†
        
        Args:
            dataset_name (str): Kaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
            
        Returns:
            pd.DataFrame: å®Ÿãƒ‡ãƒ¼ã‚¿
        """
        try:
            print(f"Kaggleã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­: {dataset_name}")
            
            # Kaggle APIè¨­å®š
            self.setup_kaggle_api()
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            download_path = os.path.join(self.data_dir, "kaggle_raw")
            os.makedirs(download_path, exist_ok=True)
            
            # kaggle datasets download
            kaggle.api.dataset_download_files(
                dataset_name, 
                path=download_path, 
                unzip=True
            )
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã—ã¦èª­ã¿è¾¼ã¿
            csv_files = [f for f in os.listdir(download_path) if f.endswith('.csv')]
            
            if not csv_files:
                raise FileNotFoundError("CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # æœ€åˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            csv_path = os.path.join(download_path, csv_files[0])
            df_raw = pd.read_csv(csv_path)
            
            print(f"å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df_raw)}ä»¶")
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«: {csv_files[0]}")
            print(f"   åˆ—: {list(df_raw.columns)}")
            
            # Amazon ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
            df_converted = self._convert_kaggle_to_amazon_format(df_raw)
            
            return df_converted
            
        except Exception as e:
            print(f"Kaggle API ã‚¨ãƒ©ãƒ¼: {e}")
            print("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ä»£æ›¿ã—ã¾ã™...")
            return self._generate_sample_data()
    
    
    def _convert_kaggle_to_amazon_format(self, df_kaggle: pd.DataFrame) -> pd.DataFrame:
        """
        Kaggleãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
        
        Args:
            df_kaggle (pd.DataFrame): Kaggleç”Ÿãƒ‡ãƒ¼ã‚¿
            
        Returns:
            pd.DataFrame: çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        """
        print("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ä¸­...")
        
        # åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¿œã˜ã¦èª¿æ•´ï¼‰
        column_mapping = {
            # Amazon Fine Food Reviews ã®å ´åˆ
            'Id': 'review_id',
            'ProductId': 'product_id', 
            'UserId': 'user_id',
            'Score': 'rating',
            'Summary': 'review_title',
            'Text': 'review_text',
            'Time': 'review_date'
        }
        
        # åˆ—åå¤‰æ›´
        df_converted = df_kaggle.rename(columns=column_mapping)
        
        # å¿…è¦ãªåˆ—ã®ç¢ºèªãƒ»è¿½åŠ 
        required_columns = ['product_id', 'rating', 'review_text']
        missing_columns = [col for col in required_columns if col not in df_converted.columns]
        
        if missing_columns:
            print(f"âš ï¸ ä¸è¶³åˆ—ã‚’è£œå®Œ: {missing_columns}")
            
            # ä¸è¶³åˆ—ã®è£œå®Œ
            if 'product_id' in missing_columns:
                df_converted['product_id'] = df_converted.index.map(lambda x: f"B{x:06d}")
            if 'rating' in missing_columns:
                df_converted['rating'] = 5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            if 'review_text' in missing_columns:
                df_converted['review_text'] = "No review text available"
        
        # å•†å“åãƒ»ã‚«ãƒ†ã‚´ãƒªã®æ¨å®šï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãï¼‰
        df_converted['product_name'] = self._estimate_product_names(df_converted)
        df_converted['product_category'] = self._estimate_categories(df_converted)
        
        # æ—¥ä»˜ã®å‡¦ç†
        if 'review_date' in df_converted.columns:
            # Unixæ™‚é–“ã‚’æ­£ã—ãå¤‰æ›
            df_converted['review_date'] = pd.to_datetime(df_converted['review_date'], unit='s', errors='coerce')
        # unit='s' ã‚’æŒ‡å®šã—ã¦Unixç§’ã‚’æ­£ã—ãå¤‰æ›
        elif 'Time' in df_converted.columns:
            # å…ƒã®Timeåˆ—ã‹ã‚‰ã®å¤‰æ›
            df_converted['review_date'] = pd.to_datetime(df_converted['Time'], unit='s', errors='coerce')
        else:
            # ãƒ©ãƒ³ãƒ€ãƒ ãªæ—¥ä»˜ç”Ÿæˆ
            df_converted['review_date'] = pd.date_range(
                start='2023-01-01', 
                end='2024-12-31', 
                periods=len(df_converted)
            )
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
        df_converted['helpful_votes'] = np.random.randint(0, 20, len(df_converted))
        df_converted['total_votes'] = df_converted['helpful_votes'] + np.random.randint(0, 10, len(df_converted))
        df_converted['verified_purchase'] = np.random.choice([True, False], len(df_converted), p=[0.8, 0.2])
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®èª¿æ•´
        df_converted['rating'] = pd.to_numeric(df_converted['rating'], errors='coerce')
        df_converted = df_converted.dropna(subset=['rating'])
        df_converted['rating'] = df_converted['rating'].astype(int)
        
        # è©•ä¾¡ã®ç¯„å›²èª¿æ•´ï¼ˆ1-5ã«æ­£è¦åŒ–ï¼‰
        df_converted['rating'] = df_converted['rating'].clip(1, 5)
        
        print(f"ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›å®Œäº†: {len(df_converted)}ä»¶")
        return df_converted
    
    def _estimate_product_names(self, df: pd.DataFrame) -> pd.Series:
        """å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å•†å“åã‚’æ¨å®šï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        
        def extract_product_name(text, summary="", product_id=""):
            if pd.isna(text):
                text = ""
            if pd.isna(summary):
                summary = ""
                
            text_lower = str(text).lower()
            summary_lower = str(summary).lower()
            
            # 1. ã‚µãƒãƒªãƒ¼ã‹ã‚‰å•†å“åæŠ½å‡ºï¼ˆã‚ˆã‚Šå…·ä½“çš„ï¼‰
            if summary and len(summary) > 3:
                # ã‚µãƒãƒªãƒ¼ã¯å•†å“åã«è¿‘ã„å ´åˆãŒå¤šã„
                return str(summary)[:50]  # é•·ã™ãã‚‹å ´åˆã¯çŸ­ç¸®
            
            # 2. ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
            product_keywords = {
                'coffee': ['coffee', 'espresso', 'latte', 'cappuccino'],
                'tea': ['tea', 'green tea', 'black tea', 'herbal'],
                'snack': ['chips', 'crackers', 'nuts', 'cookies'],
                'candy': ['candy', 'chocolate', 'gum', 'sweet'],
                'food': ['sauce', 'pasta', 'rice', 'cereal']
            }
            
            for category, keywords in product_keywords.items():
                for keyword in keywords:
                    if keyword in text_lower:
                        return f"{keyword.title()}"
            
            # 3. ProductIDã®æ´»ç”¨
            if product_id:
                return f"Product {product_id}"
            
            return "Unknown Food Product"
        
        # è¤‡æ•°åˆ—ã‚’æ´»ç”¨
        if 'review_text' in df.columns:
            return df.apply(lambda row: extract_product_name(
                row.get('review_text', ''),
                row.get('review_title', ''),
                row.get('product_id', '')
            ), axis=1)
        else:
            return pd.Series(["Unknown Product"] * len(df))

    def _estimate_categories(self, df: pd.DataFrame) -> pd.Series:
        """å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æ¨å®š"""
        
        def categorize_review(text, summary=""):
            if pd.isna(text):
                text = ""
            if pd.isna(summary):
                summary = ""
            
            text_lower = str(text).lower() + " " + str(summary).lower()
            
            # ã‚ˆã‚Šè©³ç´°ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†é¡
            if any(word in text_lower for word in ['coffee', 'tea', 'beverage', 'drink', 'juice', 'soda']):
                return 'beverages'
            elif any(word in text_lower for word in ['snack', 'chip', 'candy', 'cookie', 'cracker', 'nuts']):
                return 'snacks'
            elif any(word in text_lower for word in ['food', 'sauce', 'spice', 'pasta', 'rice', 'meat']):
                return 'food'
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€ã‚‚ä¸€èˆ¬çš„ãªã‚«ãƒ†ã‚´ãƒª
                return 'food'
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚µãƒãƒªãƒ¼ã®ä¸¡æ–¹ã‚’ä½¿ç”¨
        if 'review_text' in df.columns and 'review_title' in df.columns:
            return df.apply(lambda row: categorize_review(row['review_text'], row['review_title']), axis=1)
        elif 'review_text' in df.columns:
            return df['review_text'].apply(lambda x: categorize_review(x))
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ©ãƒ³ãƒ€ãƒ ã ãŒè­¦å‘Š
            print("âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼šã‚«ãƒ†ã‚´ãƒªã‚’ãƒ©ãƒ³ãƒ€ãƒ æ¨å®š")
            categories = ['food', 'beverages', 'snacks']
            return pd.Series(np.random.choice(categories, len(df)))
        
    def load_kaggle_dataset(self, dataset_name: str = "amazon_reviews", use_real_data: bool = True) -> pd.DataFrame:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ï¼ˆæ›´æ–°ç‰ˆï¼‰
        
        Args:
            dataset_name (str): ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
            use_real_data (bool): å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            
        Returns:
            pd.DataFrame: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
        """
        if use_real_data:
            try:
                # å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦è¡Œ
                return self.load_real_kaggle_dataset("snap/amazon-fine-food-reviews")
            except Exception as e:
                print(f"å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
                print("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ä»£æ›¿ã—ã¾ã™...")
                return self._generate_sample_data()
        else:
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨
            print("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
            return self._generate_sample_data()

    def _generate_sample_data(self, n_samples: int = 3000) -> pd.DataFrame:
        """
        ç¾å®Ÿçš„ãªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        
        Args:
            n_samples (int): ç”Ÿæˆã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3000ä»¶ï¼‰
            
        Returns:
            pd.DataFrame: ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
        """
        print(f"{n_samples}ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        
        # ä¹±æ•°ã®ã‚·ãƒ¼ãƒ‰è¨­å®š
        np.random.seed(42)
        
        # å•†å“ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        products = []
        for category, items in self.target_categories.items():
            for item in items:
                products.append({
                    "name": item,        # å•†å“å
                    "category": category # ã‚«ãƒ†ã‚´ãƒª
                })
        
        # ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ«ãƒ¼ãƒ—
        data = []
        
        # tqdm: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
        for i in tqdm(range(n_samples), desc="ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­"):
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ©ãƒ³ãƒ€ãƒ ã«å•†å“ã‚’é¸æŠ
            product = np.random.choice(products)
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: ç¾å®Ÿçš„ãªè©•ä¾¡åˆ†å¸ƒã§è©•ä¾¡ã‚’ç”Ÿæˆ
            # å®Ÿéš›ã®Amazonã¯é«˜è©•ä¾¡ãŒå¤šã„ã®ã§ã€ãã‚Œã‚’åæ˜ 
            rating = np.random.choice(
                [1, 2, 3, 4, 5],                    # è©•ä¾¡å€¤
                p=[0.05, 0.10, 0.15, 0.35, 0.35]   # å„è©•ä¾¡ã®å‡ºç¾ç¢ºç‡
            )
            # 5ç‚¹ãŒ35%ã€4ç‚¹ãŒ35%ã€3ç‚¹ãŒ15%ã€2ç‚¹ãŒ10%ã€1ç‚¹ãŒ5%
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: è©•ä¾¡ã«å¿œã˜ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            review_text = self._generate_review_text(rating, product["name"])
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒªã‚¢ãƒ«ãªæ—¥ä»˜ç”Ÿæˆ
            start_date = datetime.now() - timedelta(days=365)
            random_days = np.random.randint(0, 365)
            review_date = start_date + timedelta(days=random_days)
            
            # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
            record = {
                # å•†å“æƒ…å ±
                "product_id": f"B{i:06d}",                    # å•†å“IDï¼ˆB000001å½¢å¼ï¼‰
                "product_name": product["name"],              # å•†å“å
                "product_category": product["category"],      # ã‚«ãƒ†ã‚´ãƒª
                
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±  
                "review_id": f"R{i:08d}",                    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ID
                "rating": rating,                            # è©•ä¾¡ï¼ˆ1-5ï¼‰
                "review_text": review_text,                  # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè¿½åŠ æƒ…å ±ï¼‰
                "helpful_votes": np.random.randint(0, 50),   # ã€Œå½¹ã«ç«‹ã£ãŸã€ç¥¨æ•°
                "total_votes": np.random.randint(0, 100),    # ç·æŠ•ç¥¨æ•°
                "verified_purchase": np.random.choice(       # è³¼å…¥ç¢ºèªæ¸ˆã¿ã‹
                    [True, False], p=[0.85, 0.15]           # 85%ãŒç¢ºèªæ¸ˆã¿
                ),
                "review_date": review_date                   # ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥ä»˜
            }
            
            # ãƒªã‚¹ãƒˆã«ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ 
            data.append(record)
        
        # ãƒªã‚¹ãƒˆã‚’DataFrameã«å¤‰æ›
        df = pd.DataFrame(data)
        print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(df)}ä»¶")
        return df
    
    def _generate_review_text(self, rating: int, product_name: str) -> str:
        """
        è©•ä¾¡ã«åŸºã¥ããƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        
        Args:
            rating (int): è©•ä¾¡ï¼ˆ1-5ï¼‰
            product_name (str): å•†å“å
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ
        """
        
        if rating >= 4:
            # é«˜è©•ä¾¡ï¼ˆ4-5ç‚¹ï¼‰ã®å ´åˆ
            base_text = np.random.choice(self.positive_patterns)
            
            # å•†å“ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸå…·ä½“çš„ãªã‚³ãƒ¡ãƒ³ãƒˆè¿½åŠ 
            if "å……é›»å™¨" in product_name:
                specifics = ["å……é›»é€Ÿåº¦ãŒæ—©ã„ã§ã™ã€‚", "ã‚±ãƒ¼ãƒ–ãƒ«ã‚‚ä¸ˆå¤«ãã†ã§ã™ã€‚", "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã§æŒã¡é‹ã³ã‚„ã™ã„ã§ã™ã€‚"]
            elif "ã‚¤ãƒ¤ãƒ›ãƒ³" in product_name:
                specifics = ["éŸ³è³ªãŒã‚¯ãƒªã‚¢ã§ã™ã€‚", "ãƒ•ã‚£ãƒƒãƒˆæ„ŸãŒè‰¯ã„ã§ã™ã€‚", "é•·æ™‚é–“ä½¿ã£ã¦ã‚‚ç–²ã‚Œã¾ã›ã‚“ã€‚"]
            elif "æœ¬" in product_name:
                specifics = ["å†…å®¹ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã§ã™ã€‚", "å®Ÿè·µçš„ã§å½¹ç«‹ã¡ã¾ã™ã€‚", "èª­ã¿ã‚„ã™ã„æ§‹æˆã§ã™ã€‚"]
            else:
                specifics = ["æ©Ÿèƒ½ãŒå……å®Ÿã—ã¦ã„ã¾ã™ã€‚", "ãƒ‡ã‚¶ã‚¤ãƒ³ãŒæ°—ã«å…¥ã‚Šã¾ã—ãŸã€‚"]
            
            # åŸºæœ¬æ–‡ + å…·ä½“çš„ã‚³ãƒ¡ãƒ³ãƒˆ
            return base_text + " " + np.random.choice(specifics)
            
        elif rating <= 2:
            # ä½è©•ä¾¡ï¼ˆ1-2ç‚¹ï¼‰ã®å ´åˆ
            base_text = np.random.choice(self.negative_patterns)
            
            # å•†å“ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸå…·ä½“çš„ãªå•é¡Œç‚¹è¿½åŠ 
            if "å……é›»å™¨" in product_name:
                specifics = ["å……é›»ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚", "ã‚±ãƒ¼ãƒ–ãƒ«ãŒã™ãæ–­ç·šã—ã¾ã—ãŸã€‚", "ç™ºç†±ãŒæ°—ã«ãªã‚Šã¾ã™ã€‚"]
            elif "ã‚¤ãƒ¤ãƒ›ãƒ³" in product_name:
                specifics = ["éŸ³ãŒé€”åˆ‡ã‚Œã¾ã™ã€‚", "è€³ã«ãƒ•ã‚£ãƒƒãƒˆã—ã¾ã›ã‚“ã€‚", "éŸ³è³ªãŒæ‚ªã™ãã¾ã™ã€‚"]
            elif "æœ¬" in product_name:
                specifics = ["å†…å®¹ãŒè–„ã„ã§ã™ã€‚", "æœŸå¾…ã—ã¦ã„ãŸå†…å®¹ã¨é•ã„ã¾ã—ãŸã€‚", "èª¤å­—ãŒå¤šã„ã§ã™ã€‚"]
            else:
                specifics = ["æ©Ÿèƒ½ãŒä¸ååˆ†ã§ã™ã€‚", "ã™ãã«æ•…éšœã—ã¾ã—ãŸã€‚"]
            
            return base_text + " " + np.random.choice(specifics)
            
        else:
            # ä¸­è©•ä¾¡ï¼ˆ3ç‚¹ï¼‰ã®å ´åˆ
            return np.random.choice(self.neutral_patterns)
    
    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ãƒ»ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        
        Args:
            df (pd.DataFrame): ç”Ÿãƒ‡ãƒ¼ã‚¿
            
        Returns:
            pd.DataFrame: å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        print("ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’é–‹å§‹...")
        df_processed = df.copy()  # ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿è­·
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: æ¬ æå€¤å‡¦ç†
        print("æ¬ æå€¤å‡¦ç†ä¸­...")
        original_count = len(df_processed)
        # é‡è¦ãªåˆ—ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ã€è©•ä¾¡ï¼‰ã«æ¬ æãŒã‚ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’é™¤å¤–
        df_processed = df_processed.dropna(subset=["review_text", "rating"])
        dropped_count = original_count - len(df_processed)
        if dropped_count > 0:
            print(f"   æ¬ æå€¤ã®ã‚ã‚‹{dropped_count}ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
        print("ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†ä¸­...")
        # æ–‡å­—åˆ—ã®å‰å¾Œã®ç©ºç™½é™¤å»
        df_processed["review_text_clean"] = df_processed["review_text"].str.strip()
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ–‡å­—æ•°è¨ˆç®—
        df_processed["review_length"] = df_processed["review_text_clean"].str.len()
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: è©•ä¾¡ã®æ­£è¦åŒ–
        # 1-5ã®è©•ä¾¡ã‚’0-1ã®ç¯„å›²ã«å¤‰æ›
        df_processed["rating_normalized"] = (df_processed["rating"] - 1) / 4
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã®ä»˜ä¸
        print("æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ä»˜ä¸ä¸­...")
        df_processed["sentiment_label"] = df_processed["rating"].apply(self._rating_to_sentiment)
        
        # ã‚¹ãƒ†ãƒƒãƒ—5: æœ‰ç”¨æ€§ã®è¨ˆç®—
        # ã€Œå½¹ã«ç«‹ã£ãŸã€ç¥¨ã®å‰²åˆã‚’è¨ˆç®—
        df_processed["helpfulness_ratio"] = df_processed.apply(
            lambda x: x["helpful_votes"] / max(x["total_votes"], 1), axis=1
        )
        
        # ã‚¹ãƒ†ãƒƒãƒ—6: æ—¥ä»˜ã®å‡¦ç†
        if "review_date" in df_processed.columns:
            # æ–‡å­—åˆ—ã®æ—¥ä»˜ã‚’datetimeå‹ã«å¤‰æ›
            df_processed["review_date"] = pd.to_datetime(df_processed["review_date"])
            # å¹´ãƒ»æœˆã‚’åˆ¥åˆ—ã¨ã—ã¦æŠ½å‡ºï¼ˆæ™‚ç³»åˆ—åˆ†æã§ä½¿ç”¨ï¼‰
            df_processed["review_year"] = df_processed["review_date"].dt.year
            df_processed["review_month"] = df_processed["review_date"].dt.month
        
        # ã‚¹ãƒ†ãƒƒãƒ—7: ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã®è¿½åŠ 
        print("ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆè¨ˆç®—ä¸­...")
        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å¹³å‡è©•ä¾¡ç­‰ã‚’è¨ˆç®—ã—ã€å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«è¿½åŠ 
        category_stats = df_processed.groupby("product_category")["rating"].agg([
            "mean", "std", "count"  # å¹³å‡ã€æ¨™æº–åå·®ã€ä»¶æ•°
        ]).add_prefix("category_")
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã«çµ±è¨ˆæƒ…å ±ã‚’çµåˆ
        df_processed = df_processed.merge(
            category_stats, 
            left_on="product_category", 
            right_index=True
        )
        
        # ã‚¹ãƒ†ãƒƒãƒ—8: ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ•ãƒ©ã‚°
        # é«˜å“è³ªãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        df_processed["is_high_quality"] = (
            (df_processed["verified_purchase"] == True) &      # è³¼å…¥ç¢ºèªæ¸ˆã¿
            (df_processed["review_length"] >= 20) &            # ã‚ã‚‹ç¨‹åº¦é•·ã„
            (df_processed["total_votes"] >= 1)                 # æŠ•ç¥¨ãŒã‚ã‚‹
        )
        
        print(f"å‰å‡¦ç†å®Œäº†: {len(df_processed)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
        return df_processed
    
    def _rating_to_sentiment(self, rating: int) -> str:
        """
        è©•ä¾¡ã‚’æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã«å¤‰æ›
        
        Args:
            rating (int): è©•ä¾¡ï¼ˆ1-5ï¼‰
            
        Returns:
            str: æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ï¼ˆpositive/neutral/negativeï¼‰
        """
        if rating >= 4:
            return "positive"    # 4-5ç‚¹ï¼šãƒã‚¸ãƒ†ã‚£ãƒ–
        elif rating == 3:
            return "neutral"     # 3ç‚¹ï¼šãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«
        else:
            return "negative"    # 1-2ç‚¹ï¼šãƒã‚¬ãƒ†ã‚£ãƒ–
    
    def save_data(self, df: pd.DataFrame, filename: str = "raw_reviews.csv") -> str:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            df (pd.DataFrame): ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            filename (str): ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        filepath = os.path.join(self.data_dir, filename)
        
        try:
            # UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§CSVä¿å­˜
            df.to_csv(filepath, index=False, encoding="utf-8")
            
            # ä¿å­˜çµæœã®å ±å‘Š
            print(f"ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            print(f"   ä»¶æ•°: {len(df):,}ä»¶")
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(filepath) / 1024:.1f} KB")
            return filepath
            
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise  # ã‚¨ãƒ©ãƒ¼ã‚’ä¸Šä½ã«ä¼æ’­
    
    def load_data(self, filename: str = "raw_reviews.csv") -> pd.DataFrame:
        """
        ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            filename (str): ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            pd.DataFrame: èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        filepath = os.path.join(self.data_dir, filename)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
        
        try:
            # UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§CSVèª­ã¿è¾¼ã¿
            df = pd.read_csv(filepath, encoding="utf-8")
            print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {filepath}")
            print(f"   ä»¶æ•°: {len(df):,}ä»¶")
            return df
            
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def get_data_summary(self, df: pd.DataFrame) -> Dict:
        """
        ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦çµ±è¨ˆã‚’å–å¾—
        
        Args:
            df (pd.DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Dict: æ¦‚è¦çµ±è¨ˆæƒ…å ±ï¼ˆè¾æ›¸å½¢å¼ï¼‰
        """
        
        # åŸºæœ¬æƒ…å ±ã®è¨ˆç®—
        basic_info = {
            "total_reviews": len(df),                           # ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°
            "unique_products": df["product_id"].nunique(),      # ãƒ¦ãƒ‹ãƒ¼ã‚¯å•†å“æ•°
            "unique_categories": df["product_category"].nunique(), # ã‚«ãƒ†ã‚´ãƒªæ•°
            "date_range": {
                "start": str(df["review_date"].min()) if "review_date" in df.columns else "N/A",
                "end": str(df["review_date"].max()) if "review_date" in df.columns else "N/A"
            }
        }
        
        # è©•ä¾¡åˆ†æ
        rating_analysis = {
            "average_rating": round(df["rating"].mean(), 2),           # å¹³å‡è©•ä¾¡
            "rating_distribution": df["rating"].value_counts().sort_index().to_dict(), # è©•ä¾¡åˆ†å¸ƒ
            "rating_std": round(df["rating"].std(), 2)                 # è©•ä¾¡ã®æ¨™æº–åå·®
        }
        
        # æ„Ÿæƒ…åˆ†æ
        sentiment_analysis = {
            "sentiment_distribution": df["sentiment_label"].value_counts().to_dict() if "sentiment_label" in df.columns else {},
            "negative_ratio": round((df["sentiment_label"] == "negative").mean() * 100, 1) if "sentiment_label" in df.columns else 0
        }
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ†æ
        category_analysis = {
            "category_distribution": df["product_category"].value_counts().to_dict(),
            "category_ratings": df.groupby("product_category")["rating"].mean().round(2).to_dict()
        }
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
        text_analysis = {
            "average_review_length": round(df["review_length"].mean(), 1) if "review_length" in df.columns else 0,
            "median_review_length": round(df["review_length"].median(), 1) if "review_length" in df.columns else 0,
            "verified_purchase_ratio": round((df["verified_purchase"] == True).mean() * 100, 1) if "verified_purchase" in df.columns else 0
        }
        
        # å“è³ªæŒ‡æ¨™
        quality_metrics = {
            "high_quality_reviews": (df["is_high_quality"] == True).sum() if "is_high_quality" in df.columns else 0,
            "reviews_with_votes": (df["total_votes"] > 0).sum() if "total_votes" in df.columns else 0,
            "average_helpfulness": round(df["helpfulness_ratio"].mean(), 3) if "helpfulness_ratio" in df.columns else 0
        }
        
        # å…¨çµ±è¨ˆæƒ…å ±ã‚’ã¾ã¨ã‚ã¦è¿”ã™
        summary = {
            "basic_info": basic_info,
            "rating_analysis": rating_analysis,
            "sentiment_analysis": sentiment_analysis,
            "category_analysis": category_analysis,
            "text_analysis": text_analysis,
            "quality_metrics": quality_metrics
        }
        
        return summary
    
    def print_summary(self, df: pd.DataFrame):
        """
        ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
        
        Args:
            df (pd.DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
        """
        summary = self.get_data_summary(df)
        
        print("\n" + "="*60)
        print("AMAZON ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ æ¦‚è¦çµ±è¨ˆ")
        print("="*60)
        
        # åŸºæœ¬æƒ…å ±ã®è¡¨ç¤º
        print(f"\nğŸ“‹ åŸºæœ¬æƒ…å ±:")
        basic = summary["basic_info"]
        print(f"   ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {basic['total_reviews']:,} ä»¶")
        print(f"   ãƒ¦ãƒ‹ãƒ¼ã‚¯å•†å“æ•°: {basic['unique_products']:,} ä»¶")
        print(f"   ã‚«ãƒ†ã‚´ãƒªæ•°: {basic['unique_categories']} ç¨®é¡")
        print(f"   æœŸé–“: {basic['date_range']['start']} ï½ {basic['date_range']['end']}")
        
        # è©•ä¾¡åˆ†æã®è¡¨ç¤º
        print(f"\nè©•ä¾¡åˆ†æ:")
        rating = summary["rating_analysis"]
        print(f"   å¹³å‡è©•ä¾¡: {rating['average_rating']}/5.0")
        print(f"   è©•ä¾¡åˆ†å¸ƒ: {rating['rating_distribution']}")
        
        # æ„Ÿæƒ…åˆ†æã®è¡¨ç¤º
        print(f"\næ„Ÿæƒ…åˆ†æ:")
        sentiment = summary["sentiment_analysis"]
        print(f"   æ„Ÿæƒ…åˆ†å¸ƒ: {sentiment['sentiment_distribution']}")
        print(f"   ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡: {sentiment['negative_ratio']}%")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ†æã®è¡¨ç¤º
        print(f"\nã‚«ãƒ†ã‚´ãƒªåˆ†æ:")
        category = summary["category_analysis"]
        print(f"   ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ: {category['category_distribution']}")
        print(f"   ã‚«ãƒ†ã‚´ãƒªåˆ¥è©•ä¾¡: {category['category_ratings']}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã®è¡¨ç¤º
        print(f"\nãƒ†ã‚­ã‚¹ãƒˆåˆ†æ:")
        text = summary["text_analysis"]
        print(f"   å¹³å‡ãƒ¬ãƒ“ãƒ¥ãƒ¼é•·: {text['average_review_length']} æ–‡å­—")
        print(f"   è³¼å…¥ç¢ºèªæ¸ˆã¿ç‡: {text['verified_purchase_ratio']}%")
        
        # å“è³ªæŒ‡æ¨™ã®è¡¨ç¤º
        print(f"\nå“è³ªæŒ‡æ¨™:")
        quality = summary["quality_metrics"]
        print(f"   é«˜å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼: {quality['high_quality_reviews']} ä»¶")
        print(f"   æŠ•ç¥¨ä»˜ããƒ¬ãƒ“ãƒ¥ãƒ¼: {quality['reviews_with_votes']} ä»¶")
        print(f"   å¹³å‡æœ‰ç”¨æ€§: {quality['average_helpfulness']}")
        
        print("="*60)


def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•° - ãƒ‡ãƒ¼ã‚¿åé›†ã‹ã‚‰å‰å‡¦ç†ã¾ã§ä¸€æ‹¬å®Ÿè¡Œ
    
    1. ãƒ‡ãƒ¼ã‚¿åé›†å™¨ã®åˆæœŸåŒ–
    2. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    3. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    4. CSVä¿å­˜
    5. çµ±è¨ˆåˆ†æãƒ»å“è³ªãƒã‚§ãƒƒã‚¯
    """
    print("Amazon ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
    print("="*60)
    
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿åé›†å™¨ã®åˆæœŸåŒ–
        print("ãƒ‡ãƒ¼ã‚¿åé›†å™¨ã‚’åˆæœŸåŒ–ä¸­...")
        collector = AmazonReviewCollector()
        print("   åˆæœŸåŒ–å®Œäº†ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã€ã‚«ãƒ†ã‚´ãƒªè¨­å®šæ¸ˆã¿ï¼‰")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆï¼‰
        print("\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ä¸­...")
        df_raw = collector.load_kaggle_dataset()
        print(f"   ç”Ÿãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df_raw)}ä»¶")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        print("\nãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ä¸­...")
        df_processed = collector.preprocess_data(df_raw)
        print(f"   å‰å‡¦ç†å®Œäº†: æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã€çµ±è¨ˆé‡ç­‰ã‚’è¿½åŠ ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        print("\nãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ä¸­...")
        collector.save_data(df_raw, "raw_reviews.csv")              # ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜
        collector.save_data(df_processed, "processed_data.csv")     # å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        print("   ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜å®Œäº†")
        
        # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã®è¡¨ç¤º
        print("\nãƒ‡ãƒ¼ã‚¿æ¦‚è¦åˆ†æ:")
        collector.print_summary(df_processed)
        
        # ã‚¹ãƒ†ãƒƒãƒ—6: å“è³ªãƒã‚§ãƒƒã‚¯
        print("\nãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯:")
        quality_issues = []
        
        # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
        missing_values = df_processed.isnull().sum()
        if missing_values.any():
            quality_issues.append(f"æ¬ æå€¤: {missing_values[missing_values > 0].to_dict()}")
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼é•·ãƒã‚§ãƒƒã‚¯ï¼ˆçŸ­ã™ãã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ¤œå‡ºï¼‰
        short_reviews = (df_processed["review_length"] < 10).sum()
        if short_reviews > 0:
            quality_issues.append(f"çŸ­ã™ãã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼: {short_reviews}ä»¶")
        
        # æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«åˆ†å¸ƒãƒã‚§ãƒƒã‚¯ï¼ˆæ¥µç«¯ãªåã‚Šã®æ¤œå‡ºï¼‰
        sentiment_dist = df_processed["sentiment_label"].value_counts()
        if sentiment_dist.min() < len(df_processed) * 0.05:  # 5%æœªæº€ã®ã‚¯ãƒ©ã‚¹
            quality_issues.append("æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã®åã‚Šã‚’æ¤œå‡º")
        
        # å“è³ªãƒã‚§ãƒƒã‚¯çµæœã®è¡¨ç¤º
        if quality_issues:
            print("   å“è³ªèª²é¡Œ:")
            for issue in quality_issues:
                print(f"      - {issue}")
        else:
            print("   ãƒ‡ãƒ¼ã‚¿å“è³ªè‰¯å¥½")
        
        # ã‚¹ãƒ†ãƒƒãƒ—7: æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®æ¡ˆå†…
        print("\nPhase 1 å®Œäº†! æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("   1. æ„Ÿæƒ…åˆ†æãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ï¼ˆPhase 2ï¼‰")
        print("   2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºæ©Ÿèƒ½ã®è¿½åŠ ")
        print("   3. æ”¹å–„ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³ã®é–‹ç™º")
        print("   4. Streamlit Webã‚¢ãƒ—ãƒªã®ä½œæˆ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—8: æˆæœç‰©ã®ç¢ºèª
        print(f"\nç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
        for filename in ["raw_reviews.csv", "processed_data.csv"]:
            filepath = os.path.join(collector.data_dir, filename)
            if os.path.exists(filepath):
                size_kb = os.path.getsize(filepath) / 1024
                print(f"   {filename}: {size_kb:.1f} KB")
            else:
                print(f"   {filename}: ç”Ÿæˆå¤±æ•—")
        
        print("\nãƒ‡ãƒ¼ã‚¿åé›†ãƒ»å‰å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!")
        print("="*60)
        
        return df_processed
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®è©³ç´°æƒ…å ±è¡¨ç¤º
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:")
        import traceback
        traceback.print_exc()
        return None


def demo_analysis(df: pd.DataFrame):
    """
    ãƒ‡ãƒ¢ç”¨ã®ç°¡å˜ãªåˆ†æã‚’å®Ÿè¡Œ
    
    Args:
        df (pd.DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
    """
    print("\nãƒ‡ãƒ¢åˆ†æã‚’å®Ÿè¡Œä¸­...")
    
    # ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®åˆ†æï¼ˆæ”¹å–„ææ¡ˆã®åŸç‚¹ï¼‰
    negative_reviews = df[df["sentiment_label"] == "negative"]
    print(f"\nãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æ:")
    print(f"   ä»¶æ•°: {len(negative_reviews)}ä»¶ ({len(negative_reviews)/len(df)*100:.1f}%)")
    
    if len(negative_reviews) > 0:
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡ã®è¨ˆç®—
        negative_by_category = df.groupby("product_category").apply(
            lambda x: (x["sentiment_label"] == "negative").sum() / len(x) * 100
        ).round(1)
        
        print("   ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡:")
        for category, rate in negative_by_category.items():
            print(f"     {category}: {rate}%")
        
        # æœ€ã‚‚ãƒã‚¬ãƒ†ã‚£ãƒ–ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        worst_reviews = negative_reviews.nsmallest(3, "rating")
        print("\n   ä»£è¡¨çš„ãªãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
        for idx, (_, review) in enumerate(worst_reviews.iterrows(), 1):
            print(f"     {idx}. [{review['product_name']}] è©•ä¾¡{review['rating']}")
            print(f"        ã€Œ{review['review_text'][:50]}...ã€")
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°çµ±è¨ˆ
    print(f"\nã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°çµ±è¨ˆ:")
    category_stats = df.groupby("product_category").agg({
        "rating": ["count", "mean", "std"],        # ä»¶æ•°ã€å¹³å‡ã€æ¨™æº–åå·®
        "review_length": "mean",                   # å¹³å‡ãƒ¬ãƒ“ãƒ¥ãƒ¼é•·
        "helpfulness_ratio": "mean"                # å¹³å‡æœ‰ç”¨æ€§
    }).round(2)
    
    print(category_stats)
    
    # é«˜å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼ã®åˆ†æ
    if "is_high_quality" in df.columns:
        high_quality = df[df["is_high_quality"] == True]
        print(f"\né«˜å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æ:")
        print(f"   ä»¶æ•°: {len(high_quality)}ä»¶ ({len(high_quality)/len(df)*100:.1f}%)")
        print(f"   å¹³å‡è©•ä¾¡: {high_quality['rating'].mean():.2f}")
        
        # é«˜å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨é€šå¸¸ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ¯”è¼ƒ
        normal_quality = df[df["is_high_quality"] == False]
        print(f"   é«˜å“è³ª vs é€šå¸¸ã®å¹³å‡è©•ä¾¡: {high_quality['rating'].mean():.2f} vs {normal_quality['rating'].mean():.2f}")


def test_kaggle_integration():
    """Kaggle API çµ±åˆãƒ†ã‚¹ãƒˆ"""
    collector = AmazonReviewCollector()
    
    print("Kaggle APIçµ±åˆãƒ†ã‚¹ãƒˆ")
    
    # å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ
    df_real = collector.load_kaggle_dataset(use_real_data=True)
    print(f"å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—çµæœ: {len(df_real)}ä»¶")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ
    df_sample = collector.load_kaggle_dataset(use_real_data=False)
    print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: {len(df_sample)}ä»¶")
    
    return df_real, df_sample


def quick_test():
    """
    ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ - å°‘é‡ãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèª
    
    """
    print("ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
    
    # å°‘é‡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
    collector = AmazonReviewCollector()
    
    # 100ä»¶ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df_test = collector._generate_sample_data(n_samples=100)
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {len(df_test)}ä»¶")
    
    # å‰å‡¦ç†ãƒ†ã‚¹ãƒˆ
    df_processed = collector.preprocess_data(df_test)
    print(f"å‰å‡¦ç†å®Œäº†: {len(df_processed)}ä»¶")
    
    # åŸºæœ¬çµ±è¨ˆã®è¨ˆç®—ãƒ»è¡¨ç¤º
    summary = collector.get_data_summary(df_processed)
    print(f"çµ±è¨ˆè¨ˆç®—å®Œäº†")
    print(f"   å¹³å‡è©•ä¾¡: {summary['rating_analysis']['average_rating']}")
    print(f"   æ„Ÿæƒ…åˆ†å¸ƒ: {summary['sentiment_analysis']['sentiment_distribution']}")
    
    print("ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†!")
    return df_processed


def analyze_sample_reviews(df: pd.DataFrame, n_samples: int = 5):
    """
    ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤ºãƒ»ç¢ºèª
    
    Args:
        df (pd.DataFrame): ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
        n_samples (int): è¡¨ç¤ºã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
    """
    print(f"\nãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª (ãƒ©ãƒ³ãƒ€ãƒ  {n_samples}ä»¶):")
    print("-" * 80)
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠ
    sample_reviews = df.sample(n_samples)
    
    for idx, (_, row) in enumerate(sample_reviews.iterrows(), 1):
        print(f"{idx}. å•†å“: {row['product_name']} | ã‚«ãƒ†ã‚´ãƒª: {row['product_category']}")
        print(f"   è©•ä¾¡: {row['rating']}/5 | æ„Ÿæƒ…: {row['sentiment_label']}")
        print(f"   ãƒ¬ãƒ“ãƒ¥ãƒ¼: {row['review_text']}")
        print(f"   ãƒ¡ã‚¿: è³¼å…¥ç¢ºèª={row['verified_purchase']}, é•·ã•={row['review_length']}æ–‡å­—")
        print("-" * 80)


if __name__ == "__main__":
    """
    ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®ãƒ¡ã‚¤ãƒ³å‡¦ç†
    
    å®Ÿè¡Œæ–¹æ³•ï¼š
    1. é€šå¸¸å®Ÿè¡Œ: python src/data_collector.py
    2. ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: python -c "from src.data_collector import quick_test; quick_test()"
    """
    
    print("Amazon ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - Phase 1")
    print("ç›®çš„: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»å‰å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰")
    print("="*60)
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ
    result_df = main()
    
    # æˆåŠŸã—ãŸå ´åˆã¯ãƒ‡ãƒ¢åˆ†æã‚‚å®Ÿè¡Œ
    if result_df is not None:
        print("\nè¿½åŠ ã®ãƒ‡ãƒ¢åˆ†æã‚’å®Ÿè¡Œä¸­...")
        demo_analysis(result_df)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ç¢ºèª
        analyze_sample_reviews(result_df, n_samples=3)
    
