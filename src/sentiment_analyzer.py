"""
Amazon ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - æ„Ÿæƒ…åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ (Phase 2)

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›®çš„ï¼š
1. HuggingFace BERTã‚’ä½¿ã£ãŸé«˜ç²¾åº¦æ„Ÿæƒ…åˆ†æï¼ˆè‹±èªå¯¾å¿œï¼‰
2. 568,454ä»¶ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã«å¯¾å¿œã—ãŸå¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†
3. TF-IDFãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
4. å•é¡Œç‚¹ã®è‡ªå‹•åˆ†é¡
5. æ„Ÿæƒ…åˆ†æç²¾åº¦ã®è©•ä¾¡ãƒ»æ¤œè¨¼

å®Ÿãƒ‡ãƒ¼ã‚¿ä»•æ§˜ï¼š
- Amazon Fine Food Reviews (568kä»¶)
- è‹±èªãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿
- è©•ä¾¡: 1-5ç‚¹
- æœŸé–“: 1999-2012å¹´
"""

import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers.pipelines import pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
import gc
import os
from typing import Dict, List, Tuple, Optional
import re
from collections import defaultdict, Counter

# è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore')


class SentimentAnalyzer:
    """
    BERTæ´»ç”¨ã®æ„Ÿæƒ…åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
    
    ç‰¹å¾´:
    - å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼ˆ568kä»¶ï¼‰
    - ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
    - ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
    - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºæ©Ÿèƒ½
    - å•é¡Œåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(self, model_name: str = "cardiffnlp/twitter-roberta-base-sentiment-latest", 
                 batch_size: int = 32, device: str = "auto"):
        """
        æ„Ÿæƒ…åˆ†æå™¨ã®åˆæœŸåŒ–
        
        Args:
            model_name (str): ä½¿ç”¨ã™ã‚‹BERTãƒ¢ãƒ‡ãƒ«å
            batch_size (int): ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ¡ãƒ¢ãƒªã«å¿œã˜ã¦èª¿æ•´ï¼‰
            device (str): è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ ("auto", "cpu", "cuda")
        """
        self.model_name = model_name
        self.batch_size = batch_size
        self.device = self._setup_device(device)
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–ï¼ˆé…å»¶èª­ã¿è¾¼ã¿ï¼‰
        self.tokenizer = None
        self.model = None
        self.sentiment_pipeline = None
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºç”¨
        self.tfidf_vectorizer = None
        self.problem_keywords = None
        
        # çµæœä¿å­˜ç”¨
        self.results = {}
        
        print(f"SentimentAnalyzeråˆæœŸåŒ–å®Œäº†")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {self.model_name}")
        print(f"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {self.batch_size}")
        print(f"   ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
    
    def _setup_device(self, device: str) -> str:
        """
        è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
        
        Args:
            device (str): ãƒ‡ãƒã‚¤ã‚¹æŒ‡å®š
            
        Returns:
            str: å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹
        """
        if device == "auto":
            if torch.cuda.is_available():
                device = "cuda"
                print(f"GPUåˆ©ç”¨å¯èƒ½: {torch.cuda.get_device_name(0)}")
            else:
                device = "cpu"
                print("CPUã‚’ä½¿ç”¨")
        elif device == "cuda" and not torch.cuda.is_available():
            print("âš ï¸ CUDAæŒ‡å®šã•ã‚Œã¾ã—ãŸãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUã«å¤‰æ›´ã—ã¾ã™ã€‚")
            device = "cpu"
        
        return device
    
    def load_bert_model(self):
        """
        BERTãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆè‹±èªæ„Ÿæƒ…åˆ†æç”¨ï¼‰
        
        å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã«æœ€é©åŒ–ã•ã‚ŒãŸpipelineã‚’æ§‹ç¯‰
        """
        print(f"BERTãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {self.model_name}")
        
        try:
            # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼èª­ã¿è¾¼ã¿
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆï¼ˆãƒãƒƒãƒå‡¦ç†å¯¾å¿œï¼‰
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis",
                model=self.model,
                tokenizer=self.tokenizer,
                device=0 if self.device == "cuda" else -1,
                batch_size=self.batch_size,
                truncation=True,
                max_length=512  # BERTæœ€å¤§é•·
            )
            
            print("âœ… BERTãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è¡¨ç¤º
            if self.device == "cuda":
                print(f"   GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
            
            return True
            
        except Exception as e:
            print(f"âŒ BERTãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def analyze_sentiment_batch(self, df: pd.DataFrame, text_column: str = "review_text", 
                               chunk_size: int = 1000) -> pd.DataFrame:
        """
        å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®æ„Ÿæƒ…åˆ†æï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
        
        Args:
            df (pd.DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
            text_column (str): ãƒ†ã‚­ã‚¹ãƒˆåˆ—å
            chunk_size (int): ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚µã‚¤ã‚º
            
        Returns:
            pd.DataFrame: æ„Ÿæƒ…åˆ†æçµæœä»˜ããƒ‡ãƒ¼ã‚¿
        """
        if self.sentiment_pipeline is None:
            print("BERTãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚load_bert_model()ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return df
        
        print(f"æ„Ÿæƒ…åˆ†æé–‹å§‹: {len(df):,}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        print(f"   ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size}ä»¶")
        print(f"   æ¨å®šå‡¦ç†æ™‚é–“: {len(df) / (chunk_size * 2):.1f}åˆ†")
        
        # çµæœä¿å­˜ç”¨ãƒªã‚¹ãƒˆ
        bert_predictions = []
        bert_scores = []
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        texts = df[text_column].fillna("").astype(str).tolist()
        
        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†
        total_chunks = (len(texts) + chunk_size - 1) // chunk_size
        
        with tqdm(total=total_chunks, desc="BERTæ„Ÿæƒ…åˆ†æ") as pbar:
            for i in range(0, len(texts), chunk_size):
                chunk_texts = texts[i:i + chunk_size]
                
                try:
                    # BERTæ¨è«–å®Ÿè¡Œ
                    chunk_results = self.sentiment_pipeline(chunk_texts)
                    
                    # çµæœã®å‡¦ç†
                    for result in chunk_results: # type: ignore
                        # ãƒ©ãƒ™ãƒ«ã®æ­£è¦åŒ–ï¼ˆPOSITIVE/NEGATIVE â†’ positive/negativeï¼‰
                        label = result['label'].lower() # type: ignore
                        if 'pos' in label:
                            label = 'positive'
                        elif 'neg' in label:
                            label = 'negative'
                        else:
                            label = 'neutral'
                        
                        bert_predictions.append(label)
                        bert_scores.append(result['score']) # type: ignore
                    
                    # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    if i % (chunk_size * 10) == 0:  # 10ãƒãƒ£ãƒ³ã‚¯ã”ã¨
                        gc.collect()
                        if self.device == "cuda":
                            torch.cuda.empty_cache()
                    
                except Exception as e:
                    print(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯{i//chunk_size + 1}ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
                    for _ in chunk_texts:
                        bert_predictions.append('neutral')
                        bert_scores.append(0.5)
                
                pbar.update(1)
        
        # çµæœã‚’DataFrameã«è¿½åŠ 
        df_result = df.copy()
        df_result['bert_sentiment'] = bert_predictions
        df_result['bert_confidence'] = bert_scores
        
        # çµæœã®çµ±è¨ˆ
        bert_dist = pd.Series(bert_predictions).value_counts()
        print(f"\nâœ… BERTæ„Ÿæƒ…åˆ†æå®Œäº†")
        print(f"   å‡¦ç†ä»¶æ•°: {len(bert_predictions):,}ä»¶")
        print(f"   æ„Ÿæƒ…åˆ†å¸ƒ: {bert_dist.to_dict()}")
        print(f"   å¹³å‡ä¿¡é ¼åº¦: {np.mean(bert_scores):.3f}")
        
        return df_result
    
    def extract_keywords(self, df: pd.DataFrame, text_column: str = "review_text", 
                        sentiment_column: str = "bert_sentiment", 
                        max_features: int = 1000) -> Dict[str, List[Tuple[str, float]]]:
        """
        TF-IDF + æ„Ÿæƒ…åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        
        Args:
            df (pd.DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
            text_column (str): ãƒ†ã‚­ã‚¹ãƒˆåˆ—å
            sentiment_column (str): æ„Ÿæƒ…åˆ—å
            max_features (int): æœ€å¤§ç‰¹å¾´é‡æ•°
            
        Returns:
            Dict[str, List[Tuple[str, float]]]: æ„Ÿæƒ…åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        """
        print(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºé–‹å§‹ï¼ˆTF-IDFï¼‰")
        
        # ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
        def preprocess_text(text):
            if pd.isna(text):
                return ""
            # è‹±èªãƒ†ã‚­ã‚¹ãƒˆç”¨ã®å‰å‡¦ç†
            text = re.sub(r'[^a-zA-Z\s]', '', str(text))  # è‹±æ•°å­—ã®ã¿
            text = text.lower()  # å°æ–‡å­—å¤‰æ›
            return text
        
        df['processed_text'] = df[text_column].apply(preprocess_text)
        
        # æ„Ÿæƒ…åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        sentiment_keywords = {}
        
        for sentiment in ['positive', 'negative', 'neutral']:
            sentiment_texts = df[df[sentiment_column] == sentiment]['processed_text'].tolist()
            
            if len(sentiment_texts) == 0:
                print(f"âš ï¸ {sentiment}æ„Ÿæƒ…ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                sentiment_keywords[sentiment] = []
                continue
            
            print(f"   {sentiment}æ„Ÿæƒ…: {len(sentiment_texts):,}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            
            # TF-IDFè¨ˆç®—
            vectorizer = TfidfVectorizer(
                max_features=max_features,
                stop_words='english',
                ngram_range=(1, 2),  # 1-2ã‚°ãƒ©ãƒ 
                min_df=5,  # æœ€ä½5å›å‡ºç¾
                max_df=0.7  # 70%ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å‡ºç¾
            )
            
            try:
                tfidf_matrix = vectorizer.fit_transform(sentiment_texts)
                feature_names = vectorizer.get_feature_names_out()
                
                # é‡è¦åº¦ã®è¨ˆç®—ï¼ˆå¹³å‡TF-IDFã‚¹ã‚³ã‚¢ï¼‰
                importance_scores = tfidf_matrix.mean(axis=0).A1 # type: ignore
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨é‡è¦åº¦ã®ãƒšã‚¢ä½œæˆ
                keyword_importance = list(zip(feature_names, importance_scores))
                keyword_importance.sort(key=lambda x: x[1], reverse=True)
                
                # ä¸Šä½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä¿å­˜
                sentiment_keywords[sentiment] = keyword_importance[:50]
                
                print(f"     ä¸Šä½5ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {[kw for kw, _ in keyword_importance[:5]]}")
                
            except Exception as e:
                print(f"âš ï¸ {sentiment}æ„Ÿæƒ…ã®TF-IDFè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                sentiment_keywords[sentiment] = []
        
        # ã‚¯ãƒ©ã‚¹å¤‰æ•°ã«ä¿å­˜
        self.sentiment_keywords = sentiment_keywords
        
        print(f"âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºå®Œäº†")
        return sentiment_keywords
    
    def classify_problems(self, df: pd.DataFrame, 
                         negative_keywords: List[Tuple[str, float]]) -> pd.DataFrame:
        """
        ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å•é¡Œåˆ†é¡
        
        Args:
            df (pd.DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
            negative_keywords (List[Tuple[str, float]]): ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
            
        Returns:
            pd.DataFrame: å•é¡Œåˆ†é¡çµæœä»˜ããƒ‡ãƒ¼ã‚¿
        """
        print("å•é¡Œåˆ†é¡é–‹å§‹...")
        
        # å•é¡Œã‚«ãƒ†ã‚´ãƒªã®å®šç¾©
        problem_categories = {
            'quality': ['bad', 'terrible', 'awful', 'poor', 'worst', 'horrible', 'disgusting'],
            'price': ['expensive', 'overpriced', 'costly', 'price', 'money', 'cheap'],
            'shipping': ['shipping', 'delivery', 'arrived', 'package', 'packaging'],
            'taste': ['taste', 'flavor', 'bland', 'bitter', 'sweet', 'salty'],
            'service': ['service', 'customer', 'support', 'help', 'response']
        }
        
        # å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å•é¡Œåˆ†é¡
        def classify_review_problems(text):
            if pd.isna(text):
                return 'other'
            
            text_lower = str(text).lower()
            category_scores = {}
            
            for category, keywords in problem_categories.items():
                score = sum(1 for keyword in keywords if keyword in text_lower)
                category_scores[category] = score
            
            # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ã‚«ãƒ†ã‚´ãƒªã‚’è¿”ã™
            if max(category_scores.values()) > 0:
                return max(category_scores, key=category_scores.get) # type: ignore
            else:
                return 'other'
        
        # ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿åˆ†é¡
        negative_reviews = df[df['bert_sentiment'] == 'negative'].copy()
        
        if len(negative_reviews) > 0:
            negative_reviews['problem_category'] = negative_reviews['review_text'].apply(classify_review_problems)
            
            # å•é¡Œåˆ†å¸ƒã®è¨ˆç®—
            problem_dist = negative_reviews['problem_category'].value_counts()
            
            print(f"âœ… å•é¡Œåˆ†é¡å®Œäº†")
            print(f"   ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼: {len(negative_reviews):,}ä»¶")
            print(f"   å•é¡Œåˆ†å¸ƒ: {problem_dist.to_dict()}")
            
            # çµæœã‚’å…ƒã®DataFrameã«ãƒãƒ¼ã‚¸
            df_result = df.copy()
            df_result['problem_category'] = 'none'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            # ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®åˆ†é¡çµæœã‚’ãƒãƒ¼ã‚¸
            for idx in negative_reviews.index:
                df_result.loc[idx, 'problem_category'] = negative_reviews.loc[idx, 'problem_category']
            
            return df_result
        else:
            print("âš ï¸ ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            df['problem_category'] = 'none'
            return df
    
    def validate_predictions(self, df: pd.DataFrame) -> Dict:
        """
        BERTäºˆæ¸¬ç²¾åº¦ã®è©•ä¾¡
        
        Args:
            df (pd.DataFrame): äºˆæ¸¬çµæœä»˜ããƒ‡ãƒ¼ã‚¿
            
        Returns:
            Dict: è©•ä¾¡çµæœ
        """
        print("äºˆæ¸¬ç²¾åº¦è©•ä¾¡é–‹å§‹...")
        
        # å…ƒã®æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ï¼ˆrating-basedï¼‰ã¨BERTäºˆæ¸¬ã®æ¯”è¼ƒ
        if 'sentiment_label' not in df.columns:
            print("âš ï¸ å…ƒã®æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}
        
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
        valid_data = df[df['bert_sentiment'].notna() & df['sentiment_label'].notna()].copy()
        
        if len(valid_data) == 0:
            print("âš ï¸ æ¯”è¼ƒå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return {}
        
        y_true = valid_data['sentiment_label']
        y_pred = valid_data['bert_sentiment']
        
        # ç²¾åº¦æŒ‡æ¨™ã®è¨ˆç®—
        accuracy = accuracy_score(y_true, y_pred)
        
        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
        class_report = classification_report(y_true, y_pred, output_dict=True)
        
        # æ··åŒè¡Œåˆ—
        conf_matrix = confusion_matrix(y_true, y_pred)
        
        # çµæœã®æ•´ç†
        validation_results = {
            'accuracy': round(accuracy, 4),
            'classification_report': class_report,
            'confusion_matrix': conf_matrix.tolist(),
            'total_samples': len(valid_data),
            'label_distribution_true': y_true.value_counts().to_dict(),
            'label_distribution_pred': y_pred.value_counts().to_dict()
        }
        
        print(f"âœ… ç²¾åº¦è©•ä¾¡å®Œäº†")
        print(f"   å…¨ä½“ç²¾åº¦: {accuracy:.3f} ({accuracy*100:.1f}%)")
        print(f"   æ¯”è¼ƒä»¶æ•°: {len(valid_data):,}ä»¶")
        
        # ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦ã®è¡¨ç¤º
        for label, metrics in class_report.items(): # type: ignore
            if isinstance(metrics, dict) and label != 'accuracy':
                precision = metrics.get('precision', 0)
                recall = metrics.get('recall', 0)
                f1 = metrics.get('f1-score', 0)
                print(f"   {label}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}")
        
        self.validation_results = validation_results
        return validation_results
    
    def visualize_results(self, df: pd.DataFrame, save_plots: bool = True):
        """
        åˆ†æçµæœã®å¯è¦–åŒ–
        
        Args:
            df (pd.DataFrame): åˆ†æçµæœãƒ‡ãƒ¼ã‚¿
            save_plots (bool): ã‚°ãƒ©ãƒ•ä¿å­˜ãƒ•ãƒ©ã‚°
        """
        print("çµæœå¯è¦–åŒ–ä¸­...")
        
        # å›³ã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        plt.style.use('default')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('BERTæ„Ÿæƒ…åˆ†æçµæœ', fontsize=16, fontweight='bold')
        
        # 1. æ„Ÿæƒ…åˆ†å¸ƒæ¯”è¼ƒï¼ˆBERT vs Rule-basedï¼‰
        if 'sentiment_label' in df.columns:
            ax1 = axes[0, 0]
            
            sentiment_comparison = pd.DataFrame({
                'Rule-based': df['sentiment_label'].value_counts(),
                'BERT': df['bert_sentiment'].value_counts()
            }).fillna(0)
            
            sentiment_comparison.plot(kind='bar', ax=ax1)
            ax1.set_title('æ„Ÿæƒ…åˆ†å¸ƒæ¯”è¼ƒ: Rule-based vs BERT')
            ax1.set_xlabel('æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«')
            ax1.set_ylabel('ä»¶æ•°')
            ax1.legend()
            ax1.tick_params(axis='x', rotation=45)
        
        # 2. ä¿¡é ¼åº¦åˆ†å¸ƒ
        ax2 = axes[0, 1]
        df['bert_confidence'].hist(bins=50, ax=ax2, alpha=0.7, edgecolor='black')
        ax2.set_title('BERTäºˆæ¸¬ä¿¡é ¼åº¦åˆ†å¸ƒ')
        ax2.set_xlabel('ä¿¡é ¼åº¦')
        ax2.set_ylabel('ä»¶æ•°')
        ax2.axvline(df['bert_confidence'].mean(), color='red', linestyle='--', 
                   label=f'å¹³å‡: {df["bert_confidence"].mean():.3f}')
        ax2.legend()
        
        # 3. å•é¡Œã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        if 'problem_category' in df.columns:
            ax3 = axes[1, 0]
            problem_dist = df[df['problem_category'] != 'none']['problem_category'].value_counts()
            
            if len(problem_dist) > 0:
                problem_dist.plot(kind='pie', ax=ax3, autopct='%1.1f%%')
                ax3.set_title('ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼å•é¡Œåˆ†å¸ƒ')
            else:
                ax3.text(0.5, 0.5, 'ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã—', ha='center', va='center')
                ax3.set_title('ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼å•é¡Œåˆ†å¸ƒ')
        
        # 4. è©•ä¾¡åˆ¥æ„Ÿæƒ…åˆ†å¸ƒ
        ax4 = axes[1, 1]
        if 'rating' in df.columns:
            rating_sentiment = pd.crosstab(df['rating'], df['bert_sentiment'], normalize='index') * 100
            rating_sentiment.plot(kind='bar', stacked=True, ax=ax4)
            ax4.set_title('è©•ä¾¡åˆ¥BERTæ„Ÿæƒ…åˆ†å¸ƒ (%)')
            ax4.set_xlabel('è©•ä¾¡ (1-5)')
            ax4.set_ylabel('å‰²åˆ (%)')
            ax4.legend(title='æ„Ÿæƒ…')
            ax4.tick_params(axis='x', rotation=0)
        
        plt.tight_layout()
        
        if save_plots:
            os.makedirs('results', exist_ok=True)
            plt.savefig('results/sentiment_analysis_results.png', dpi=300, bbox_inches='tight')
            print("ğŸ“Š ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: results/sentiment_analysis_results.png")
        
        plt.show()
    
    def save_results(self, df: pd.DataFrame, filename: str = "sentiment_analysis_results.csv"):
        """
        åˆ†æçµæœã®ä¿å­˜
        
        Args:
            df (pd.DataFrame): çµæœãƒ‡ãƒ¼ã‚¿
            filename (str): ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å
        """
        os.makedirs('results', exist_ok=True)
        filepath = os.path.join('results', filename)
        
        # é‡è¦ãªåˆ—ã®ã¿é¸æŠ
        columns_to_save = [
            'product_id', 'rating', 'review_text',
            'sentiment_label', 'bert_sentiment', 'bert_confidence',
            'problem_category', 'review_length'
        ]
        
        # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ä¿å­˜
        available_columns = [col for col in columns_to_save if col in df.columns]
        df_to_save = df[available_columns].copy()
        
        df_to_save.to_csv(filepath, index=False, encoding='utf-8')
        
        print(f"ğŸ’¾ çµæœã‚’ä¿å­˜: {filepath}")
        print(f"   ä¿å­˜ä»¶æ•°: {len(df_to_save):,}ä»¶")
        print(f"   ä¿å­˜åˆ—: {available_columns}")
    
    def generate_summary_report(self, df: pd.DataFrame) -> str:
        """
        åˆ†æçµæœã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        
        Args:
            df (pd.DataFrame): åˆ†æçµæœãƒ‡ãƒ¼ã‚¿
            
        Returns:
            str: ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
        """
        report = []
        report.append("="*80)
        report.append("AMAZON ãƒ¬ãƒ“ãƒ¥ãƒ¼ BERTæ„Ÿæƒ…åˆ†æ - ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("="*80)
        
        # åŸºæœ¬çµ±è¨ˆ
        report.append(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        report.append(f"   ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {len(df):,}ä»¶")
        report.append(f"   åˆ†æå®Œäº†ç‡: {df['bert_sentiment'].notna().sum() / len(df) * 100:.1f}%")
        
        # BERTæ„Ÿæƒ…åˆ†æçµæœ
        if 'bert_sentiment' in df.columns:
            bert_dist = df['bert_sentiment'].value_counts()
            report.append(f"\nğŸ¤– BERTæ„Ÿæƒ…åˆ†æçµæœ:")
            for sentiment, count in bert_dist.items():
                percentage = count / len(df) * 100
                report.append(f"   {sentiment}: {count:,}ä»¶ ({percentage:.1f}%)")
            
            avg_confidence = df['bert_confidence'].mean()
            report.append(f"   å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}")
        
        # ç²¾åº¦è©•ä¾¡
        if hasattr(self, 'validation_results') and self.validation_results:
            accuracy = self.validation_results['accuracy']
            report.append(f"\nğŸ¯ ç²¾åº¦è©•ä¾¡:")
            report.append(f"   å…¨ä½“ç²¾åº¦: {accuracy:.3f} ({accuracy*100:.1f}%)")
        
        # å•é¡Œåˆ†æ
        if 'problem_category' in df.columns:
            negative_count = (df['bert_sentiment'] == 'negative').sum()
            problem_dist = df[df['problem_category'] != 'none']['problem_category'].value_counts()
            
            report.append(f"\nâŒ ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æ:")
            report.append(f"   ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼: {negative_count:,}ä»¶ ({negative_count/len(df)*100:.1f}%)")
            
            if len(problem_dist) > 0:
                report.append(f"   ä¸»è¦å•é¡Œ:")
                for problem, count in problem_dist.head(5).items():
                    percentage = count / negative_count * 100
                    report.append(f"     - {problem}: {count}ä»¶ ({percentage:.1f}%)")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        if hasattr(self, 'sentiment_keywords') and self.sentiment_keywords:
            report.append(f"\nğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ:")
            for sentiment in ['negative', 'positive']:
                if sentiment in self.sentiment_keywords:
                    keywords = self.sentiment_keywords[sentiment][:5]
                    keyword_list = [kw for kw, _ in keywords]
                    report.append(f"   {sentiment}ã®ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keyword_list)}")
        
        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
        report.append(f"\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ— (Phase 3):")
        report.append(f"   1. æ”¹å–„ææ¡ˆã‚¨ãƒ³ã‚¸ãƒ³ã®å®Ÿè£…")
        report.append(f"   2. ROIç®—å‡ºã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰")
        report.append(f"   3. ç«¶åˆæ¯”è¼ƒæ©Ÿèƒ½ã®è¿½åŠ ")
        report.append(f"   4. Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™º")
        
        report.append("="*80)
        
        return "\n".join(report)


def main():
    """
    Phase 2ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    
    1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    2. BERTæ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
    3. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    4. å•é¡Œåˆ†é¡
    5. ç²¾åº¦è©•ä¾¡
    6. çµæœå¯è¦–åŒ–ãƒ»ä¿å­˜
    """
    print("Phase 2: BERTæ„Ÿæƒ…åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ - å®Ÿè¡Œé–‹å§‹")
    print("="*60)
    
    try:
        # Step 1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print("Step 1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
        data_path = "data/processed_data.csv"
        
        if not os.path.exists(data_path):
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
            print("Phase 1ã®data_collector.pyã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return None
        
        df = pd.read_csv(data_path)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}ä»¶")
        
        # Step 2: æ„Ÿæƒ…åˆ†æå™¨ã®åˆæœŸåŒ–
        print("\nStep 2: BERTæ„Ÿæƒ…åˆ†æå™¨åˆæœŸåŒ–...")
        analyzer = SentimentAnalyzer(batch_size=16)  # ãƒ¡ãƒ¢ãƒªã«å¿œã˜ã¦èª¿æ•´
        
        # BERTãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        if not analyzer.load_bert_model():
            print("âŒ BERTãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
        
        # Step 3: æ„Ÿæƒ…åˆ†æå®Ÿè¡Œï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆã‹ã‚‰é–‹å§‹ï¼‰
        print("\nStep 3: BERTæ„Ÿæƒ…åˆ†æå®Ÿè¡Œ...")
        
        # æœ€åˆã¯å°‘é‡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
        test_sample_size = 1000
        print(f"âš ï¸ ã¾ãšã¯{test_sample_size:,}ä»¶ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")
        
        df_sample = df.head(test_sample_size)
        df_analyzed = analyzer.analyze_sentiment_batch(df_sample, chunk_size=100)
        
        print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«åˆ†æå®Œäº†ã€‚å…¨ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ")
        user_input = input("å…¨ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        
        if user_input.lower() == 'y':
            print("å…¨ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œä¸­...")
            df_analyzed = analyzer.analyze_sentiment_batch(df, chunk_size=500)
        else:
            print("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®åˆ†æã‚’ç¶šè¡Œ...")
        
        # Step 4: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        print("\nStep 4: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º...")
        keywords = analyzer.extract_keywords(df_analyzed)
        
        # Step 5: å•é¡Œåˆ†é¡
        print("\nStep 5: å•é¡Œåˆ†é¡...")
        negative_keywords = keywords.get('negative', [])
        df_final = analyzer.classify_problems(df_analyzed, negative_keywords)
        
        # Step 6: ç²¾åº¦è©•ä¾¡
        print("\nStep 6: ç²¾åº¦è©•ä¾¡...")
        validation_results = analyzer.validate_predictions(df_final)
        
        # Step 7: çµæœå¯è¦–åŒ–
        print("\nStep 7: çµæœå¯è¦–åŒ–...")
        analyzer.visualize_results(df_final)
        
        # Step 8: çµæœä¿å­˜
        print("\nStep 8: çµæœä¿å­˜...")
        analyzer.save_results(df_final)
        
        # Step 9: ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("\nStep 9: ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ...")
        summary_report = analyzer.generate_summary_report(df_final)
        print(summary_report)
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        os.makedirs('results', exist_ok=True)
        with open('results/phase2_summary_report.txt', 'w', encoding='utf-8') as f:
            f.write(summary_report)
        
        print("\nğŸ‰ Phase 2 å®Œäº†!")
        print("   ğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«:")
        print("      - results/sentiment_analysis_results.csv")
        print("      - results/sentiment_analysis_results.png")
        print("      - results/phase2_summary_report.txt")
        
        return df_final
        
    except Exception as e:
        print(f"\nâŒ Phase 2å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None


def quick_test():
    """
    ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
    å°‘é‡ãƒ‡ãƒ¼ã‚¿ã§ã®å‹•ä½œç¢ºèª
    """
    print("Phase 2 ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")
    
    try:
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        test_data = pd.DataFrame({
            'review_text': [
                "This product is amazing! I love it so much.",
                "Terrible quality. Very disappointed.",
                "It's okay, nothing special.",
                "Worst purchase ever. Complete waste of money.",
                "Great value for money. Highly recommended!"
            ],
            'rating': [5, 1, 3, 1, 5],
            'sentiment_label': ['positive', 'negative', 'neutral', 'negative', 'positive']
        })
        
        print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_data)}ä»¶")
        
        # åˆ†æå™¨åˆæœŸåŒ–
        analyzer = SentimentAnalyzer(batch_size=2)
        
        if analyzer.load_bert_model():
            # æ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
            result = analyzer.analyze_sentiment_batch(test_data)
            
            # çµæœè¡¨ç¤º
            print("\nãƒ†ã‚¹ãƒˆçµæœ:")
            for i, row in result.iterrows():
                print(f"  {i+1}. [{row['rating']}â˜…] {row['sentiment_label']} â†’ {row['bert_sentiment']} ({row['bert_confidence']:.3f})") # type: ignore
                print(f"     ã€Œ{row['review_text'][:50]}...ã€")
            
            print("\nâœ… ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†!")
            return result
        else:
            print("âŒ ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå¤±æ•—")
            return None
            
    except Exception as e:
        print(f"âŒ ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


if __name__ == "__main__":
    """
    Phase 2ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
    
    å®Ÿè¡Œæ–¹æ³•:
    1. é€šå¸¸å®Ÿè¡Œ: python src/sentiment_analyzer.py
    2. ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: python -c "from src.sentiment_analyzer import quick_test; quick_test()"
    """
    
    print("Amazon ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - Phase 2")
    print("ç›®çš„: BERTæ„Ÿæƒ…åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®æ§‹ç¯‰")
    print("="*60)
    
    # ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‹ã‚‰é–‹å§‹
    print("ã¾ãšã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (æ¨å¥¨)")
    test_choice = input("ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ? (y/n): ")
    
    if test_choice.lower() == 'y':
        test_result = quick_test()
        if test_result is not None:
            print("\nãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ")
            main_choice = input("ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ? (y/n): ")
            if main_choice.lower() == 'y':
                main()
    else:
        main()